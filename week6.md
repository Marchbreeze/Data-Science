## 1. 가명 정보와 데이터 식별화

### (1) 국내법의 정보 분류

1. 개인 정보
    - 주소, 폰번호 등 특정 개인에 관한 정보
    - 사전에 구체적인 동의를 받아야만 제한된 범위에서 활용 가능
    - ex. 김상호 / 25세 / 산업공학과

1. 가명 정보
    - 추가 정보가 주어지지 않으면 개인을 알아볼 수 없는 정보
    - 추가 정보 : 암호화 당시 쓰인 키, 가명 처리 시 활용된 매핑 테이블, 가명 처리 알고리즘의 파라미터, …
    - 연구, 통계 작성 등에 한해 동의없이 활용 가능
    - ex. 김XX / 2X세 / XX학과

1. 익명 정보
    - 추가 정보가 주어져도 개인을 전혀 알아볼 수 없는 정보
    - 활용 목적에 무관하게 자유롭게 활용 가능 (개인정보보호법의 적용 대상 X)
    - ex. XXX / XX세 / XX학과

### (2) 데이터 비식별화

- 데이터 비식별화 (De-Identification | Anonymization)
    - 데이터 내에 개인 식별이 가능한 정보가 존재하는 경우, 
    해당 정보의 일부 혹은 전부를 삭제하거나 대체하는 등의 행위를 취함으로써 
    결과적으로 ‘다른 데이터와 결합한다고 하더라도’ 개인을 식별하기 어렵게끔 만드는 것
    - 식별 방지를 통한 비식별화 & 추론 방지를 통한 비식별화로 구분
        
        ![2024-04-20_01-09-47.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/9cf6fe46-a1be-4e21-a50a-db45b09ecdf5/2024-04-20_01-09-47.jpg)
        

- 비식별화의 중요성 사례
    - Netflix는 영화 추천 알고리즘의 정확도를 높이기 위해 경연대회를 개최
        
        → 1999년 ~ 2005년 자사 이용자 50만 명의 평점 및 시청 이력 데이터 공개
        
    - University of Texas at Austin의 연구 그룹이 개인 식별에 성공 - by IMDb의 공개 리뷰를 결합

### (3) 식별 방지를 위한 비식별화 방법

1. Data Masking
    - 특정 항목의 일부 또는 전체를 공백 또는 * / _ / x 등의 문자로 대체
    - ex. 010 – 1234 – 5678 → 010 – 1xx4 – 5xx8

1. Aggregation
    - 평균, 중앙값, 최빈값, 최솟값, 최댓값 등 대푯값 하나로 모든 값을 통일

1. Categorization
    - 문자형 데이터에 대하여 보다 상위의 개념으로 범주화
    - ex. Galaxy Z Fold4 / Galaxy S23 / Galaxy S24 → Galaxy / Galaxy / Galaxy

1. Rounding
    - 올림, 내림, 반올림 등을 적용
    - 적절히 자릿수를 선택해야 함에 유의
        - 값마다 Rounding의 자릿수를 랜덤으로 조정 (Random Rounding)
    - 전체 합과 평균이 라운딩에 의해서 왜곡될 수 있음
        - 적절하게 제어해서 통계값이 왜곡되지 않도록 보정 필요 → (5)

1. Controlled Rounding 
    - 임의적인 조작을 통해 Rounding에서 통계값 보존
    - Rounding 수행 전후 데이터의 누계가 달라지지 않게끔 일부 값을 택해 제어
    
2. Tokenization
    - 특정 정보를 암호화 등의 방법을 거쳐 토큰으로 변환하는 방법
    - ex. 010 – 1234 – 5678 → 153829658326
    - ex. 안심번호 변환

1. Noise Addition
    - 주어진 데이터에 (정해진 확률분포를 따르는) 노이즈 값을 추가하여 비식별화
    - 데이터가 왜곡될 수 있음
    - ex. 15,310원 / 28,850원 / 482,770원 → 15,280원 / 28,920원 / 482,910원

1. Permutation
    - 동질집합 내 값의 순서를 무작위로 재배열하는 비식별화 방법
    - 동질집합 외 값의 순서를 재배열하는 경우 통계값이 왜곡될 가능성이 존재함
    - 원본 데이터를 크게 훼손할 수 있음에 유의
    - ex. (서울/30/1), (서울/29/2), (경기/35/1), (경기/49/2) - 동질집합 : 서울2, 경기2
        
          → (서울/29/1), (서울/30/2), (경기/49/1), (경기/35/2)
        

---

## 2. 추론 방지를 위한 프라이버시 모델

### (1) k-익명성 모델

- 모든 식별자가 자기 자신과 동일하여 구분이 불가능한 경우가 k 개 이상 존재
- 안전도를 보장하는 최소 k=3 (5 ≤ k ≤ 10에서 높은 안전도)
- 예시 :
    - 부상이 민감정보인 경우 → (식별자는 제외) 준식별자들의 조합을 통해 구분 불가능한 경우의 개수 확인
        
        ⇒ k가 4인 익명성 충족함 (k = 5 익명성 충족 X : 최소 경우수를 확인해야)
        
    
    ![2024-04-20_01-22-46.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/1d0b5fdb-7fa9-4a3a-9c6e-0de974e96ee6/2024-04-20_01-22-46.jpg)
    

- 공격당할 수 있는 소지?
    1. 동질성 공격
        - Europe/20~30/PL 인 선수 X는 5개 정보 중 어느 정보인지는 몰라도, 햄스트링 부상을 알 수 있음
    2. 배경지식 공격
        - SerieA 소속인 선수 Y가 정상 무릎이라는 정보를 알고있는 경우, Y의 부상은 타박상임을 알 수 있음
        

### (2) l-다양성 모델

- 식별자가 동일해 구분이 불가능한 데이터(동질집합)들은, 적어도 l개의 서로 다른 민감정보를 가져야 함
- 동질성 공격에 대한 방어가 가능
- 예시 :
    - Europe/20~30/PL 인 동질집합 : 3 - 다양성을 가짐
    - Africa/20~30/SerieA 인 동질집합 : 2 - 다양성을 가짐
        
        ⇒ 해당 데이터셋은 4 - 익명성, 2 - 다양성을 충족함
        
    
    ![2024-04-20_01-32-35.jpg](https://prod-files-secure.s3.us-west-2.amazonaws.com/edfd69d1-6c01-4d0c-9269-1bae8a4e3915/5759768d-8771-45ae-974f-8a755d92166f/2024-04-20_01-32-35.jpg)
    
- 공격당할 수 있는 소지?
    1. 유사성 공격
        - Europe/20~30/PL 인 선수 X는 5개 정보 중 어느 정보인지는 몰라도, 하반신 부상을 알 수 있음
        - 민감정보가 다양하다 하더라도, 정보들 간 유사성이 있는 경우 어느정도의 정보를 제공하게 됨
    2. 쏠림 공격
        - Africa/20~30/SerieA 인 선수 Y는 높은 확률로 타박상 부상임을 추측할 수 있음
        - 민감정보가 다양하다 하더라도, 특정 정보에 쏠려있으면 확률 상의 정보를 제공하게 됨

### (3) 재귀 (c, l) 다양성

- 다음 두 조건 (가), (나)를 모두 만족하는 경우
    - (가) l – 다양성을 가짐
    - (나) 동질집합 내 민감정보 빈도의 내림차순이 r1, r2, ..., rm일 때, (r1 = 가장 큰 값)
           모든 동질집합에 대해 r1 < c (r2+...+ rm)이 성립
- 쏠림 공격에 대한 방어 가능
- 위 예시 : c = 4, l = 2 → 재귀 (1,2) 다양성을 만족하지 못함 → 나이 범위 조정 등 조치가 필요

---

## 3. 신뢰할 수 있는 인공지능의 특성

### (1) 인공지능 윤리

- 사법부에서의 유죄 판결 증거
    - 미사법부는 과거 유죄 판결을 받은 적이 있는 이들의 재범 가능성을 추정하기 위하여 COMPAS 알고리즘 활용 → 흑인 집단이 백인 집단보다 고위험 판정을 받을 가능성이 2배 결론
    - 인공지능 분석에 기반해 재범 위험성이 높다고 판단하여 중형을 선고했으나 피고인의 데이터셋 및 방법 공개 요구가 거절된 것이 논란을 촉발함
    - 증거가 아닌 예측..!

- 인공지능 윤리 기준 마련
    1. EU
        - 19년 <신뢰가능한 AI 윤리 가이드라인> 공개 - AI의 3가지 속성, 7가지 요구 사항 제안
    2. 한국
        - 20년 <사람이 중심이 되는 인공지능 윤리기준> 발표 - 3대 기본 원칙, 10대 핵심 요건 제안

### (2) EU가 제시한 신뢰가능 AI의 3가지 속성

1. 적법성 (Lawful)
    - 구속력을 갖는 모든 법령과 규정을 준수해야 함
2. 윤리성 (Ethical)
    - 구속력 여부와 무관하게 윤리적 가치에 부합해야 함
3. 견고성 (Robust)
    - 선한 목적이더라도, 비의도적 피해를 야기해서는 안됨

### (3) EU가 제시한 신뢰가능 AI의 7가지 요구사항

1. 인간 행위자와 감독
    - 인간의 감독을 허용해야 하며, 감독권이 적을수록 거버넌스는 엄격해야 함
2. 기술적 경고성, 안전성
    - AI에 의한 의도치 않은 위해를 최소화해야 하며, 악의적 행위자도 고려해야 함
3. 프라이버시 & 데이터 거버넌스
    - 학습하기에 적합한 충분한 품질의 데이터셋과 그 무결성을 확보해야 함
4. 투명성
    - 데이터셋 및 의사결정 프로세스는 추적가능해야 하며 설명가능해야 함
5. 다양성과 차별 금지 & 공정성
    - 가능하다면 데이터 수집 단계에서 차별적 편향을 선제적으로 제거하여야 함
6. 사회적-환경적 웰빙
    - 사회제도, 민주주의 등 사회적 관점에서의 AI 영향력 평가도 실시되어야 함
7. 책임성
    - AI 시스템의 부적절성을 신고할 경우, 그에 대한 정당한 보호가 따라야 함
